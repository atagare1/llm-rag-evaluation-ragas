# ğŸ¤– LLM RAG Evaluation using RAGAS + Together AI

This project demonstrates an evaluation pipeline for **Retrieval-Augmented Generation (RAG)** using the [RAGAS](https://github.com/explodinggradients/ragas) framework, with inference powered by **open-source LLMs hosted on [Together AI](https://www.together.ai/)**.

---

## ğŸš€ Key Features

* ğŸ” Evaluate RAG pipelines using **RAGAS**
* ğŸ’¸ Switch from expensive GPT APIs to **Together AI** (e.g., `Mixtral`, `LLaMA`, `Zephyr`)
* ğŸ§ª Simplified `pytest`-based test setup using `conftest.py`
* ğŸ” Easy model switching via environment variables

---

## ğŸ“¦ Installation

1. **Clone the repository**

```bash
git clone https://github.com/atagare1/llm-rag-evaluation-ragas.git
cd llm-rag-evaluation-ragas
```

2. **Create and activate a virtual environment**

```bash
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
```

3. **Install dependencies**

```bash
pip install -r requirements.txt
```

---

## ğŸ” Secure API Setup

Create a `.env` file in the root directory:

```env
OPENAI_API_KEY=your_together_ai_key
OPENAI_BASE_URL=https://api.together.xyz/v1
```

Ensure `.env` is **ignored** in version control:

```gitignore
.env
```

---

## âš™ï¸ Test Configuration with Together AI (`conftest.py`)

We use a `pytest` fixture to load the LLM from Together AI. It uses environment variables to remain secure and flexible.

### `conftest.py`

```python
import os
import pytest
from langchain.chat_models import ChatOpenAI
from dotenv import load_dotenv

load_dotenv()  # Load .env at runtime

@pytest.fixture
def llm_wrapper():
    """
    LLM fixture using Together AI-hosted open models.
    """
    llm = ChatOpenAI(
        model="mistralai/Mixtral-8x7B-Instruct-v0.1",
        temperature=0.7
    )
    return llm
```

---

## âœ… Sample Test

```python
def test_llm_response(llm_wrapper):
    response = llm_wrapper.predict("What is RAG?")
    assert isinstance(response, str)
    assert "retrieval" in response.lower()
```

Run with:

```bash
pytest
```

---

## ğŸ†– Why Together AI Over OpenAI (ChatGPT)?

| Feature            | Together AI                                | OpenAI (ChatGPT)                    |
| ------------------ | ------------------------------------------ | ----------------------------------- |
| ğŸ’¸ Cost            | Free & affordable OSS models               | Expensive for GPT-4 & large volumes |
| ğŸ”„ Model Switching | Supports OSS models (Mixtral, LLaMA, etc.) | Proprietary only (GPT-3.5, GPT-4)   |
| ğŸš€ Performance     | Fast, scalable inference                   | Limited based on pricing tier       |
| ğŸ§  Transparency    | Open weights & training specs              | Black-box models                    |

---

## ğŸ“Š Future Enhancements

* Integrate RAGAS metrics into test reports
* Utilise RAGAS dashboard
* Add benchmarking across multiple models (e.g., `Mixtral` vs `LLaMA`)
* Plug into CI/CD with GitHub Actions



